# 主流的模型优化方法

### 学习目标

* 掌握主流的模型优化方法和对应的案例。



模型优化的三大方向

* 模型指标优化

* 模型训练性能优化

* 模型预测性能优化


---


### 1.模型指标优化

* 这里的模型指标，是指评定最终模型优劣的指标，如常用的ACC，AUC，F1，precision，recall，mAP等等。

* 为了能够提升这些指标，我们往往从以下几个方面考虑：
	* 训练数据
	* 模型结构
	* 损失函数
	* 可解释性

---

* 训练数据：
	* 往往清洗或增强训练数据是最直接和有效的指标提升方式，也是工业界最常用的方式。
	* 对于清洗脏数据，主要的理论依据便是从业务角度出发，对数据的合理性进行业务解析，然后编写相关的代码逻辑，最后进行对比实验。
	* 对于数据增强则需要考虑的更多一些，需要在验证集上进行badcase分析，不同的badcase代表着模型不同的弱点，然后针对性的增强数据，如何增强呢，EDA（同义词替换）和回译法都是常见的方法。

---

* 模型结构：
	* 一般情况下，官方发布的模型都具有成熟的结构，比如：transformer或resnet，不建议直接修改这些模型的网络结构。
	* 那模型结构如何改变呢，我们可以使用级联（Cascade）的方式，多个标准模型可以分享输入，然后使用损失和作为最终的损失，比如wide-deep；也可以多个标准模型串行，后面的模型基于前面的模型弱点进行强化，比如：先分类，后检测。


---

* 损失函数：
	* 其实在Cascade模型结构时，我们就需要用到自定义损失函数，不过，那种自定义比较简单，只是多个已有标准损失的和。
	* 而去真正进行深度的自定义损失函数需要很多过程，首先需要对优化目标进行业务剖析，从另外一个角度找到其优化的方向，比如，除了希望输出的标签和真实标签越来越接近以外，还希望输出的词向量能够满足语序关系。而这种优化方向还需要你的模型输出和已有数据的配合，比如bert除了能输出标签外，就天然能够输出词向量，而为了满足语序关系可以使用NER的损失函数（前提是你也已经有了NER的标注数据）。
	* 最后，建议损失函数的修改还是从简单的运算（加减乘除）开始，或者标准损失的累加，因为损失函数之后需要施加优化器，需要考虑可导性。


---


### 2.模型训练性能优化

* 一般情况下，训练是离线的，实时性要求不高，因此其优化也不是考核的重点。但假如可以做到准实时训练，对于产品应用来讲，也是非常有益的。

* 模型训练性能优化从以下几个方面考虑：
	* 硬件加速
	* 数据分布式
	* 模型分布式	
	* 迁移学习


---


### 3.模型预测性能优化

* 对于模型预测阶段的性能优化是业界的热点问题，不能满足性能要求的模型几乎不可被使用，比如在移动端使用大型模型。


* 模型预测性能优化从以下几个方面考虑：
	* 模型压缩
	* 硬件加速
	* 并行预测
	* 模型融合（model fuse）

---





