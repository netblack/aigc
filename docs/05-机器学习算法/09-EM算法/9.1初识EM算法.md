# 9.1 初识EM算法

## 学习目标

- 知道什么是EM算法

------



EM算法也称期望最大化（Expectation-Maximum,简称EM）算法。

**它是一个基础算法，是很多机器学习领域算法的基础，**比如隐式马尔科夫算法（HMM）等等。

EM算法是一种迭代优化策略，由于它的计算方法中每一次迭代都分两步，

- **其中一个为期望步（E步），**
- **另一个为极大步（M步），**

所以算法被称为EM算法（Expectation-Maximization Algorithm）。

---

EM算法受到缺失思想影响，**最初是为了解决数据缺失情况下的参数估计问题**，其算法基础和收敛有效性等问题在Dempster、Laird和Rubin三人于1977年所做的文章《Maximum likelihood from incomplete data via the EM algorithm》中给出了详细的阐述。其基本思想是：

- 首先**根据己经给出的观测数据，估计出模型参数的值**；
- 然后**再依据上一步估计出的参数值估计缺失数据的值**，再根据估计出的缺失数据加上之前己经观测到的数据**重新再对参数值进行估计**；
- 然后反复迭代，直至最后收敛，迭代结束。



**EM算法计算流程：**

![image-20191209171743726](https://tva1.sinaimg.cn/large/006tNbRwly1g9qlbcwzqlj319a0oigpv.jpg)



------

## 小结

- EM算法是一种迭代优化策略，由于它的计算方法中每一次迭代都分两步：
    - **其中一个为期望步（E步）**
    - **另一个为极大步（M步）**