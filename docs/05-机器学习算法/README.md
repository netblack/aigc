# 机器学习算法课程定位、目标

## 定位

- 课程以算法、案例为驱动的学习，伴随浅显易懂的数学知识
- 作为人工智能领域的提升课程，掌握更深更有效的解决问题技能

## 目标

- 掌握机器学习常见算法原理
- 应用Scikit-learn实现机器学习算法的应用，
- 结合场景解决实际问题



## 目录

## 01-K-近邻算法

- [1.1K-近邻算法简介](01-K-近邻算法/1.1K-近邻算法简介)
- [1.2k近邻算法api初步使用](01-K-近邻算法/1.2k近邻算法api初步使用)
- [1.3距离度量](01-K-近邻算法/1.3距离度量)
- [1.4k值的选择](01-K-近邻算法/1.4k值的选择)
- [1.5kd树](01-K-近邻算法/1.5kd树)
- [1.6鸢尾花种类预测-数据集介绍](01-K-近邻算法/1.6鸢尾花种类预测-数据集介绍)
- [1.7特征工程-特征预处理](01-K-近邻算法/1.7特征工程-特征预处理)
- [1.8鸢尾花种类预测-流程实现](01-K-近邻算法/1.8鸢尾花种类预测-流程实现)
- [1.9k-近邻算法总结](01-K-近邻算法/1.9k-近邻算法总结)
- [1.10交叉验证，网格搜索](01-K-近邻算法/1.10交叉验证，网格搜索)
- [1.11预测facebook签到位置](01-K-近邻算法/1.11预测facebook签到位置)
- [1.12拓展阅读：其他距离公式](01-K-近邻算法/1.12拓展阅读：其他距离公式)
- [1.13知识补充：再议数据分割](01-K-近邻算法/1.13知识补充：再议数据分割)

## 02-线性回归

- [2.1线性回归简介](02-线性回归/2.1线性回归简介)
- [2.2线性回归api初步使用](02-线性回归/2.2线性回归api初步使用)
- [2.3数学-求导](02-线性回归/2.3数学-求导)
- [2.4线性回归的损失和优化](02-线性回归/2.4线性回归的损失和优化)
- [2.5梯度下降法方法介绍](02-线性回归/2.5梯度下降法方法介绍)
- [2.6线性回归api再介绍](02-线性回归/2.6线性回归api再介绍)
- [2.7案例：波士顿房价预测](02-线性回归/2.7案例：波士顿房价预测)
- [2.8欠拟合和过拟合](02-线性回归/2.8欠拟合和过拟合)
- [2.9正则化线性模型](02-线性回归/2.9正则化线性模型)
- [2.10线性回归的改进-岭回归](02-线性回归/2.10线性回归的改进-岭回归)
- [2.11模型的保存和加载](02-线性回归/2.11模型的保存和加载)
- [2.12拓展阅读：正规方程推导拓展](02-线性回归/2.12拓展阅读：正规方程推导拓展)
- [2.13拓展阅读：梯度下降法算法比较和进一步优化](02-线性回归/2.13拓展阅读：梯度下降法算法比较和进一步优化)
- [2.14拓展阅读：维灾难](02-线性回归/2.14拓展阅读：维灾难)

## 03-逻辑回归

- [3.1逻辑回归介绍](03-逻辑回归/3.1逻辑回归介绍)
- [3.2逻辑回归api介绍](03-逻辑回归/3.2逻辑回归api介绍)
- [3.3案例：乳腺癌肿瘤预测](03-逻辑回归/3.3案例：乳腺癌肿瘤预测)
- [3.4分类评估方法](03-逻辑回归/3.4分类评估方法)
- [3.5ROC曲线的绘制](03-逻辑回归/3.5ROC曲线的绘制)
- [3.6知识补充：分类中解决类别不平衡问题](03-逻辑回归/3.6知识补充：分类中解决类别不平衡问题)

## 04-决策树算法

- [4.1决策树算法简介](04-决策树算法/4.1决策树算法简介)
- [4.2决策树分类原理](04-决策树算法/4.2决策树分类原理)
- [4.3cart剪枝](04-决策树算法/4.3cart剪枝)
- [4.4特征工程-特征提取](04-决策树算法/4.4特征工程-特征提取)
- [4.5决策树算法api](04-决策树算法/4.5决策树算法api)
- [4.6案例：泰坦尼克号乘客生存预测](04-决策树算法/4.6案例：泰坦尼克号乘客生存预测)
- [4.7回归决策树](04-决策树算法/4.7回归决策树)

## 05-集成学习基础

- [5.1集成学习算法简介](05-集成学习基础/5.1集成学习算法简介)
- [5.2Bagging和随机森林](05-集成学习基础/5.2Bagging和随机森林)
- [5.3随机森林案例](05-集成学习基础/5.3随机森林案例)
- [5.4Boosting介绍](05-集成学习基础/5.4Boosting介绍)
- [5.5GBDT介绍](05-集成学习基础/5.5GBDT介绍)
- [5.6拓展阅读：无偏估计](05-集成学习基础/5.6拓展阅读：无偏估计)

## 06-聚类算法

- [6.1聚类算法简介](06-聚类算法/6.1聚类算法简介)
- [6.2聚类算法api初步使用](06-聚类算法/6.2聚类算法api初步使用)
- [6.3聚类算法实现流程](06-聚类算法/6.3聚类算法实现流程)
- [6.4模型评估](06-聚类算法/6.4模型评估)
- [6.5算法优化](06-聚类算法/6.5算法优化)
- [6.6特征工程-特征降维](06-聚类算法/6.6特征工程-特征降维)
- [6.7案例：探究用户对物品类别的喜好聚类](06-聚类算法/6.7案例：探究用户对物品类别的喜好聚类)
- [6.8算法选择指导](06-聚类算法/6.8算法选择指导)

## 07-朴素贝叶斯

- [7.1朴素贝叶斯算法简介](07-朴素贝叶斯/7.1朴素贝叶斯算法简介)
- [7.2概率基础复习](07-朴素贝叶斯/7.2概率基础复习)
- [7.3案例：商品评论情感分析](07-朴素贝叶斯/7.3案例：商品评论情感分析)
- [7.4朴素贝叶斯算法总结](07-朴素贝叶斯/7.4朴素贝叶斯算法总结)

## 08-支持向量机

- [8.1SVM算法简介](08-支持向量机/8.1SVM算法简介)
- [8.2SVM算法api初步使用](08-支持向量机/8.2SVM算法api初步使用)
- [8.3SVM算法原理](08-支持向量机/8.3SVM算法原理)
- [8.4SVM的损失函数](08-支持向量机/8.4SVM的损失函数)
- [8.5SVM的核方法](08-支持向量机/8.5SVM的核方法)
- [8.6SVM回归](08-支持向量机/8.6SVM回归)
- [8.7SVM算法api再介绍](08-支持向量机/8.7SVM算法api再介绍)
- [8.8SVM案例实践](08-支持向量机/8.8SVM案例实践)
- [8.9SVM总结](08-支持向量机/8.9SVM总结)
- [8.10拓展阅读：向量与矩阵的范数](08-支持向量机/8.10拓展阅读：向量与矩阵的范数)
- [8.11拓展阅读：朗格朗日乘子法举例](08-支持向量机/8.11拓展阅读：朗格朗日乘子法举例)

## 09-EM算法

- [9.1初识EM算法](09-EM算法/9.1初识EM算法)
- [9.2EM算法介绍](09-EM算法/9.2EM算法介绍)
- [9.3EM算法实例](09-EM算法/9.3EM算法实例)
- [9.4拓展阅读：极大似然函数取对数的原因](09-EM算法/9.4拓展阅读：极大似然函数取对数的原因)

## 10-HMM模型

- [10.1马尔科夫链](10-HMM模型/10.1马尔科夫链)
- [10.2HMM简介](10-HMM模型/10.2HMM简介)
- [10.3HMM模型基础](10-HMM模型/10.3HMM模型基础)
- [10.4前向后向算法评估观察序列概率](10-HMM模型/10.4前向后向算法评估观察序列概率)
- [10.5维特比算法解码隐藏状态序列](10-HMM模型/10.5维特比算法解码隐藏状态序列)
- [10.6鲍姆-韦尔奇算法简介](10-HMM模型/10.6鲍姆-韦尔奇算法简介)
- [10.7HMM模型API介绍](10-HMM模型/10.7HMM模型API介绍)

## 11-集成学习进阶

- [11.1xgboost算法原理](11-集成学习进阶/11.1xgboost算法原理)
- [11.2xgboost算法api介绍](11-集成学习进阶/11.2xgboost算法api介绍)
- [11.3xgboost案例介绍](11-集成学习进阶/11.3xgboost案例介绍)
- [11.4otto案例介绍--xgboost实现](11-集成学习进阶/11.4otto案例介绍--xgboost实现)
- [11.5lightGBM算法原理](11-集成学习进阶/11.5lightGBM算法原理)
- [11.6lightGBM算法api介绍](11-集成学习进阶/11.6lightGBM算法api介绍)
- [11.7lightGBM案例介绍](11-集成学习进阶/11.7lightGBM案例介绍)
- [11.8《绝地求生》玩家排名预测](11-集成学习进阶/11.8《绝地求生》玩家排名预测)
- [11.9拓展学习：stacking算法基本思想](11-集成学习进阶/11.9拓展学习：stacking算法基本思想)

