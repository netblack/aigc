# 10.4 前向后向算法评估观察序列概率

## 学习目标

- 知道用前向算法求HMM观测序列的概率
- 知道用后向算法求HMM观测序列的概率

------



本节我们就关注HMM第一个基本问题的解决方法，即已知模型和观测序列，求观测序列出现的概率。

## 1 回顾HMM问题一：求观测序列的概率

首先我们回顾下HMM模型的问题一。这个问题是这样的。

我们已知HMM模型的参数λ=(A,B,Π)。

> 其中A是隐藏状态转移概率的矩阵，
>
> B是观测状态生成概率的矩阵，
>
> Π是隐藏状态的初始概率分布。

同时我们也已经得到了观测序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgfuzhf7j308201g0sk.jpg" alt="image-20200609232851319" style="zoom:50%;" />,

现在我们要求观测序列O在模型λ 下出现的条件概率P(O|λ)。

乍一看，这个问题很简单。因为我们知道**所有的隐藏状态之间的转移概率和所有从隐藏状态到观测状态生成概率**，那么我们是可以暴力求解的。

我们可以列举出所有可能出现的长度为T的隐藏序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmghp01a9j307o01mglf.jpg" alt="image-20200609233037476" style="zoom:50%;" />,分别求出这些隐藏序列与观测序列的<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgfuzhf7j308201g0sk.jpg" alt="image-20200609232851319" style="zoom:50%;" />联合概率分布P(O,i|λ)，这样我们就可以很容易的求出边缘分布了P(O|λ)。



---

具体暴力求解的方法是这样的：

- 首先，任意隐藏序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgi3ops1j307o01mglf.jpg" alt="image-20200609233100760" style="zoom:50%;" />

- 出现的概率是：<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgiwyqghj30ho022mx7.jpg" alt="image-20200609233147981" style="zoom:50%;" />

    

- 对于固定的状态序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgi3ops1j307o01mglf.jpg" alt="image-20200609233100760" style="zoom:50%;" />，我们要求的观察序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgfuzhf7j308201g0sk.jpg" alt="image-20200609232851319" style="zoom:50%;" />出现的概率是：$$P(O|i,\lambda )=b_{i1}(o_1)b_{i2}(o_2)...b_{iT}(o_T)$$

    

- 则O和i联合出现的概率是：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slj91238j30v6030mxg.jpg" alt="image-20191211105629553" style="zoom:50%;" />

- 然后求边缘概率分布，即可得到观测序列O在模型λ 下出现的条件概率P(O|λ )P(O|λ )：


<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sliqg1bnj30we03ijrs.jpg" alt="image-20191211105559358" style="zoom: 50%;" />



虽然上述方法有效，但是如果我们的隐藏状态数N非常多的那就麻烦了，此时我们预测状态有N<sup>T</sup>种组合，算法的时间复杂度是O(TN<sup>T</sup>)阶的。

因此对于一些隐藏状态数极少的模型，我们可以用暴力求解法来得到观测序列出现的概率，但是如果隐藏状态多，则上述算法太耗时，我们需要寻找其他简洁的算法。

**前向后向算法**就是来帮助我们在较低的时间复杂度情况下求解这个问题的。



## 2 用前向算法求HMM观测序列的概率

前向后向算法是前向算法和后向算法的统称，这两个算法都可以用来求HMM观测序列的概率。我们先来看看前向算法是如何求解这个问题的。

### 2.1 流程梳理

前向算法本质上属于动态规划的算法，也就是我们要通过找到局部状态递推的公式，这样一步步的从子问题的最优解拓展到整个问题的最优解。

- 在前向算法中，通过定义“前向概率”来定义动态规划的这个局部状态。

- 什么是前向概率呢, 其实定义很简单：**定义时刻t时隐藏状态为q<sub>i</sub>, 观测状态的序列为<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgqhfpsej306a01amwy.jpg" alt="image-20200609233904245" style="zoom:50%;" />的概率为前向概率。**记为：

    - <img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slmvd9loj30fw02g749.jpg" alt="image-20191211105957494" style="zoom:50%;" />

- 既然是动态规划，我们就要递推了，现在假设我们已经找到了在时刻t时各个隐藏状态的前向概率，现在我们需要递推出时刻t+1时各个隐藏状态的前向概率。


- 我们可以基于时刻t时各个隐藏状态的前向概率，再乘以对应的状态转移概率，即<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgt0vj23j30900343yi.jpg" alt="image-20200609234130735" style="zoom:25%;" />就是在时刻t观测到<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgqzhmxaj306a01amwy.jpg" alt="image-20200609233928757" style="zoom:50%;" />，并且时刻t隐藏状态q<sub>j</sub> 时刻t+1隐藏状态q<sub>i</sub>的概率。


- 如果将下面所有的线对应的概率求和，即<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slp8yvkfj304g0383ye.jpg" alt="image-20191211110215169" style="zoom: 50%;" />就是在时刻t观测到<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgqhfpsej306a01amwy.jpg" alt="image-20200609233904245" style="zoom:50%;" />，并且时刻t+1隐藏状态q<sub>i</sub>的概率。
- 继续一步，由于观测状态o<sub>t+1</sub>只依赖于t+1时刻隐藏状态q<sub>i</sub>, 这样<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slrgxh3ej308a02w0sp.jpg" alt="image-20191211110423244" style="zoom:50%;" />就是在时刻t+1观测到<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmh5pi1ndj308401gq2r.jpg" alt="image-20200609235341597" style="zoom:50%;" />，并且时刻t+1隐藏状态的q<sub>i</sub>概率。
- 而这个概率，恰恰就是时刻t+1对应的隐藏状态i的前向概率，这样我们得到了前向概率的递推关系式如下：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slsz81imj30es03k74d.jpg" alt="image-20191211110550740" style="zoom:50%;" />

我们的动态规划从时刻1开始，到时刻T结束，由于α<sub>T</sub>(i)表示在时刻T观测序列为，<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgqhfpsej306a01amwy.jpg" alt="image-20200609233904245" style="zoom:50%;" />并且时刻T隐藏状态q<sub>i</sub>的概率，我们只要将所有隐藏状态对应的概率相加，即<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slux5d62j303i02y0sl.jpg" alt="image-20191211110741849" style="zoom:50%;" />就得到了在时刻T观测序列为<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmgqhfpsej306a01amwy.jpg" alt="image-20200609233904245" style="zoom:50%;" />的概率。

### 2.2 算法总结。

- 输入：HMM模型 λ=(A,B,Π)，观测序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmh6owuqcj3090018t8k.jpg" alt="image-20200609235438949" style="zoom:50%;" />

- 输出：观测序列概率P(O|λ)
    - 1) 计算时刻1的各个隐藏状态前向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slxk9vcfj30g002mjrd.jpg" alt="image-20191211111014281" style="zoom:50%;" />
    - 2) 递推时刻2,3,... ...T时刻的前向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slyiv27sj30m003yweo.jpg" alt="image-20191211111110223" style="zoom:50%;" />
    - 3) 计算最终结果：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slzfz1n3j30ai03oq2x.jpg" alt="image-20191211111203339" style="zoom:50%;" />

从递推公式可以看出，我们的算法时间复杂度是O(TN<sup>2</sup>)，比暴力解法的时间复杂度O(TN<sup>T</sup>)少了几个数量级。



## 3 HMM前向算法求解实例

这里我们用前面盒子与球的例子来显示前向概率的计算。
我们的观察集合是:

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm14k71rj30b2026q2t.jpg" alt="image-20191211111340320" style="zoom:50%;" />



我们的状态集合是：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm1g43oej30h402mglm.jpg" alt="image-20191211111356587" style="zoom:50%;" />

而观察序列和状态序列的长度为3.

初始状态分布为：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm1tntqyj30aa0223ye.jpg" alt="image-20191211111420238" style="zoom:50%;" />

状态转移概率分布矩阵为：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm26sp0lj30cs05caa8.jpg" alt="image-20191211111441386" style="zoom:50%;" />

观测状态概率矩阵为：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm2lvf05j309q0560sr.jpg" alt="image-20191211111505163" style="zoom:50%;" />



球的颜色的观测序列:

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm2y282ij309m026t8k.jpg" alt="image-20191211111524899" style="zoom:50%;" />



---

按照我们上一节的前向算法。首先计算时刻1三个状态的前向概率：

时刻1是红色球，

- 隐藏状态是盒子1的概率为：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm3i4qkhj30hc020aa2.jpg" alt="image-20191211111557445" style="zoom:50%;" />



- 隐藏状态是盒子2的概率为：


<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm3tc19ij30h602qq2z.jpg" alt="image-20191211111615472" style="zoom:50%;" />



- 隐藏状态是盒子3的概率为：


<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm451hk2j30hs02qdfw.jpg" alt="image-20191211111633922" style="zoom:50%;" />



---

现在我们可以开始递推了，首先递推时刻2三个状态的前向概率：

时刻2是白色球，

- 隐藏状态是盒子1的概率为：

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm4jm98tj311u03o74q.jpg" alt="image-20191211111657376" style="zoom:50%;" />



- 隐藏状态是盒子2的概率为：


<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm52w872j311u03kgm2.jpg" alt="image-20191211111727858" style="zoom:50%;" />



- 隐藏状态是盒子3的概率为：


<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9sm5fgju5j312k03m0t6.jpg" alt="image-20191211111748653" style="zoom:50%;" />



---

继续递推，现在我们递推时刻3三个状态的前向概率：

时刻3是红色球，

- 隐藏状态是盒子1的概率为：

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbnw3rq1ijj3162046myy.jpg" alt="image-20200207155502905" style="zoom:50%;" />



- 隐藏状态是盒子2的概率为：

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbnw5c8vj2j314y044jt6.jpg" alt="image-20200207155633244" style="zoom:50%;" />



- 隐藏状态是盒子3的概率为：

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbnw67mr2qj315g03mwg8.jpg" alt="image-20200207155724101" style="zoom:50%;" />



最终我们求出观测序列:O=红，白，红的概率为：

<img src="https://tva1.sinaimg.cn/large/0082zybply1gbnw6xvf1aj30e803qmxn.jpg" alt="image-20200207155805682" style="zoom:50%;" />





---

## 4 用后向算法求HMM观测序列的概率

### 4.1 流程梳理

熟悉了用前向算法求HMM观测序列的概率，现在我们再来看看怎么用后向算法求HMM观测序列的概率。

后向算法和前向算法非常类似，都是用的动态规划，唯一的区别是选择的局部状态不同，后向算法用的是“后向概率”。

### 4.2 后向算法流程

以下是后向算法的流程,注意下和前向算法的相同点和不同点：

- 输入：HMM模型 λ=(A,B,Π)，观测序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmh6owuqcj3090018t8k.jpg" alt="image-20200609235438949" style="zoom:50%;" />
- 输出：观测序列概率P(O|λ)
    - 初始化时刻T的各个隐藏状态后向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9splnmsnjj30bu026q2u.jpg" alt="image-20191211131712030" style="zoom:50%;" />
    - 递推时刻T−1,T−2,...1时刻的后向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9splxjscnj30kq03omxc.jpg" alt="image-20191211131727431" style="zoom:50%;" />
    - 计算最终结果：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9spm94d9jj30dm03ut8s.jpg" alt="image-20191211131746630" style="zoom:50%;" />

此时我们的算法时间复杂度仍然是O(TN<sup>2</sup>)



------

## 5 小结

- 前向算法求HMM观测序列
    - 输入：HMM模型 λ=(A,B,Π)，观测序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmh6owuqcj3090018t8k.jpg" alt="image-20200609235438949" style="zoom:50%;" />
    - 输出：观测序列概率P(O|λ)
        - 1) 计算时刻1的各个隐藏状态前向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slxk9vcfj30g002mjrd.jpg" alt="image-20191211111014281" style="zoom:50%;" />
        - 2) 递推时刻2,3,... ...T时刻的前向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slyiv27sj30m003yweo.jpg" alt="image-20191211111110223" style="zoom:50%;" />
        - 3) 计算最终结果：<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9slzfz1n3j30ai03oq2x.jpg" alt="image-20191211111203339" style="zoom:50%;" />

- 后向算法求HMM观测序列

    - 输入：HMM模型 λ=(A,B,Π)，观测序列<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gfmh6owuqcj3090018t8k.jpg" alt="image-20200609235438949" style="zoom:50%;" />
    - 输出：观测序列概率P(O|λ)
        - 初始化时刻T的各个隐藏状态后向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9splnmsnjj30bu026q2u.jpg" alt="image-20191211131712030" style="zoom:50%;" />
        - 递推时刻T−1,T−2,...1时刻的后向概率：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9splxjscnj30kq03omxc.jpg" alt="image-20191211131727431" style="zoom:50%;" />
        - 计算最终结果：<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1g9spm94d9jj30dm03ut8s.jpg" alt="image-20191211131746630" style="zoom:50%;" />

    