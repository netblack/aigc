# 06-模型评估

## 学习目标

- 了解机器学习中模型评估的方法
- 知道过拟合、欠拟合发生情况

------

模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。

按照**数据集的目标值不同**，可以把模型评估分为**分类模型评估和回归模型评估。**

## 1 分类模型评估

![](https://tva1.sinaimg.cn/large/e6c9d24ely1h2ic73nyqnj20vq0iuwfk.jpg)

- **准确率**
    - 预测正确的数占样本总数的比例。
- 其他评价指标：精确率、召回率、F1-score、AUC指标等

## 2 回归模型评估

![](https://tva1.sinaimg.cn/large/e6c9d24ely1h2ic75agb4j21ha0u0gof.jpg)

**均方根误差（Root Mean Squared Error，RMSE）**

- RMSE是一个衡量回归模型误差率的常用公式。 不过，它仅能比较误差是相同单位的模型。

  $$RMSE= \sqrt{\frac{\sum_{i=0}^N(p_1-a_1)^2}{n}}$$

> a 为真实值；p 为预测值



举例：

```
假设上面的房价预测，只有五个样本，对应的
真实值为：100,120,125,230,400
预测值为：105,119,120,230,410
```

那么使用均方根误差求解得：
$$
RMSE=\sqrt{\frac{[(100-105)^2+(120-119)^2+5^2+0^2+10^2]}{5}}
=5.495
$$

-----

其他评价指标：

- 相对平方误差（Relative Squared Error，RSE）、
- 平均绝对误差（Mean Absolute Error，MAE)、
- 相对绝对误差（Relative Absolute Error，RAE)



## 3 拟合

模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类：过拟合、欠拟合。

在训练过程中，你可能会遇到如下问题：

**训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？**

当算法在某个数据集当中出现这种情况，可能就出现了拟合问题。

### 3.1 欠拟合

![image-20190312213119759](https://tva1.sinaimg.cn/large/e6c9d24ely1h2ic7673c7j212m0l8ace.jpg)

因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。

**欠拟合（under-fitting）**：**模型学习的太过粗糙**，连**训练集中的样本数据特征关系都没有学出来**。

### 3.2 过拟合

![è¿æå](https://tva1.sinaimg.cn/large/e6c9d24ely1h2ic74l42xj21740ocn04.jpg)

机器已经基本能区别天鹅和其他动物了。然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。

**过拟合**（over-fitting）：所建的机器学习模型或者是深度学习模型在训练样本中**表现得过于优越**，导致在**测试数据集中表现不佳**。

- 上问题解答：
    - 训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？

## 4 小结

- 分类模型评估【了解】
    - 准确率
- 回归模型评估【了解】
    - RMSE -- 均方根误差
- 拟合【知道】
    - 举例 -- 判断是否是人
    - 欠拟合
        - 学习到的东西太少
        - 模型学习的太过粗糙
    - 过拟合
        - 学习到的东西太多
        - 学习到的特征多，不好泛化

